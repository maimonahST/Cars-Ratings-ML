{"cells":[{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import seaborn as sns\n","import matplotlib.pylab as plt\n","#%matplotlib inline\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn import preprocessing\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.impute import SimpleImputer\n","\n","from scipy.stats import norm\n","from scipy import stats\n","from sklearn.impute import KNNImputer\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_recall_fscore_support as score\n","\n","#DS\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","#KNN\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","#GradientBoostingClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","#LogisticRegressionCV\n","from sklearn.linear_model import LogisticRegressionCV\n","\n","#RandomForestClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["#loading the data from CSV file \n","data=pd.read_csv('finalDataset.csv')\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The range of feature inputs are within 0.0 to 1.0\n"]}],"source":["# Create a MinMaxScaler object for numrical data\n","scaler = MinMaxScaler()\n","\n","# Scaling the raw input features \n","feature_cols=data.columns[:-1]\n","X= scaler.fit_transform(data[feature_cols])\n","\n","print(f\"The range of feature inputs are within {X.min()} to {X.max()}\")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training dataset shape, X_train: (217, 19), y_train: (217,)\n","Testing dataset shape, X_test: (94, 19), y_test: (94,)\n"]}],"source":["\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","# Get the split indexes\n","strat_shuf_split = StratifiedShuffleSplit(n_splits=1, \n","                                          test_size=0.3, random_state=0)\n","\n","train_idx, test_idx = next(strat_shuf_split.split(data[feature_cols], data['Rate']))\n","\n","# Create the dataframes\n","X_train = data.loc[train_idx, feature_cols]\n","y_train = data.loc[train_idx, 'Rate']\n","\n","X_test  = data.loc[test_idx, feature_cols]\n","y_test  = data.loc[test_idx, 'Rate']\n","\n","print(f\"Training dataset shape, X_train: {X_train.shape}, y_train: {y_train.shape}\")\n","print(f\"Testing dataset shape, X_test: {X_test.shape}, y_test: {y_test.shape}\")"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["5    0.718894\n","4    0.161290\n","3    0.092166\n","1    0.009217\n","0    0.009217\n","2    0.009217\n","Name: Rate, dtype: float64"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts(normalize=True)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["5    0.723404\n","4    0.159574\n","3    0.085106\n","2    0.010638\n","1    0.010638\n","0    0.010638\n","Name: Rate, dtype: float64"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["y_test.value_counts(normalize=True)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# DecisionTreeClassifier\n","#importing the classfier\n","clf=DecisionTreeClassifier(random_state=0)\n","clf2=clf.fit(X_train,y_train)\n","\n","pred = clf2.predict(X_test)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyper-param:  {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","Best estimator:  DecisionTreeClassifier(max_depth=6, random_state=0)\n","Best score:  0.977061310782241\n"]}],"source":["# DecisionTree opt\n","\n","\n","#optimization\n","param_grid={\n","\"max_depth\":[2,4,6],\n","\"min_samples_split\":[2,5,10],\n","\"min_samples_leaf\":[1,2,4]}\n","grid_search= GridSearchCV(estimator=clf,param_grid=param_grid,cv=5)\n","\n","grid_search.fit(X_train,y_train)\n","print(\"Best hyper-param: \",grid_search.best_params_ )\n","print(\"Best estimator: \",grid_search.best_estimator_ )\n","print(\"Best score: \",grid_search.best_score_ )"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=9)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=9)</pre></div></div></div></div></div>"],"text/plain":["KNeighborsClassifier(n_neighbors=9)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["# KNN\n","#importing the classfier\n","\n","kCls=KNeighborsClassifier(n_neighbors=9)\n","kCls.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["# GradientBoostingClassifier\n","#importing the classfier\n","\n","gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.1, max_features=4, max_depth=2, random_state=0)\n","gb_clf2.fit(X_train, y_train)\n","predictions = gb_clf2.predict(X_test)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tuned hpyerparameters :(best parameters)  {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n","accuracy : 0.9538961038961039\n","Best estimator:  LogisticRegression(solver='newton-cg')\n"]}],"source":["#LogisticRegression\n","\n","#Grid search cross validation\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\",\"elasticnet\"], 'solver'  : ['newton-cg', 'lbfgs', 'liblinear']}\n","logreg=LogisticRegression()\n","lr=GridSearchCV(logreg,grid,cv=10)\n","lr.fit(X_train,y_train)\n","\n","a=lr.best_params_\n","b=lr.best_score_\n","print(\"tuned hpyerparameters :(best parameters) \",lr.best_params_)\n","print(\"accuracy :\",lr.best_score_)\n","print(\"Best estimator: \",lr.best_estimator_ )\n","\n","\n","#LogisticRegression\n","#from sklearn.linear_model import LogisticRegressionCV\n","#lr= LogisticRegressionCV(Cs=a['C'], penalty=a['penalty'], solver=a['solver']).fit(X_train, y_train)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["#RandomForestClassifier\n","RF= RandomForestClassifier(criterion=\"gini\",\n","                           max_depth=8,\n","                           min_samples_split=10,\n","                           random_state= 200)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["\n","def report( y_test, pred ):\n","    #report \n","    print(classification_report(y_test,pred,target_names=['0','1','2','3','4','5']))\n","\n","\n","def confusionMatrix():\n","    #confusion_matrix\n","    #the result will show how mwny sucessful predition and wrong from each class\n","\n","    cm = confusion_matrix(y_test, pred)\n","    plt.figure(figsize=(10,7))\n","\n","    sns.heatmap(cm, annot=True, fmt='.2g', cmap='Blues')\n","\n","    # TN   FP\n","    # FN   TP"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"DecisionTreeClassifier(random_state=0)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: DecisionTreeClassifier(random_state=0)","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[45], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     metrics \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(metrics, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m     metrics\n\u001b[0;32m---> 27\u001b[0m PredictionAndPerformance()\n","Cell \u001b[0;32mIn[45], line 18\u001b[0m, in \u001b[0;36mPredictionAndPerformance\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m y_pred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(y_pred, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m models:\n\u001b[1;32m     17\u001b[0m     \u001b[39m# Preciision, recall, f-score from the multi-class support function\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     precision, recall, fscore, _ \u001b[39m=\u001b[39m score(y_test, y_pred[i], average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[39m# The usual way to calculate accuracy\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred[i])\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: DecisionTreeClassifier(random_state=0)"]}],"source":["\n","\n","models=[clf2,kCls,gb_clf2,gb_clf2,lr,RF]\n","\n","labels=['DecisionTreeClassifier','KNeighborsClassifier','GradientBoostingClassifier','LogisticRegressionCV','RandomForestClassifier']\n","\n","metrics=[]\n","\n","\n","def PredictionAndPerformance():\n","    y_pred =[]\n","    \n","    for lab,mod in zip(labels, models):\n","        y_pred.append(pd.Series(mod.predict(X_test), name=lab))\n","\n","    y_pred = pd.concat(y_pred, axis=1)\n","\n","    for i in models:\n","        # Preciision, recall, f-score from the multi-class support function\n","        precision, recall, fscore, _ = score(y_test, y_pred[i], average='weighted')\n","\n","        # The usual way to calculate accuracy\n","        accuracy = accuracy_score(y_test, y_pred[i])\n","        metrics.append(pd.Series({'precision':precision, 'recall':recall,'fscore':fscore, 'accuracy':accuracy}))\n","\n","    metrics = pd.concat(metrics, axis=1)\n","    metrics\n","\n","PredictionAndPerformance()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
