{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\reham\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","import seaborn as sns\n","import matplotlib.pylab as plt\n","from imblearn.over_sampling import SMOTE\n","#%matplotlib inline\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn import preprocessing\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import StratifiedKFold\n","\n","from scipy.stats import norm\n","from scipy import stats\n","from sklearn.impute import KNNImputer\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_recall_fscore_support as score\n","\n","#DS\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","#KNN\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","#GradientBoostingClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","#LogisticRegressionCV\n","from sklearn.linear_model import LogisticRegressionCV\n","\n","#RandomForestClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 1. Loading the dataset"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#loading the data from CSV file \n","data=pd.read_csv('final_Binary.csv')\n","data.head()\n","\n","'''dataFeatures= ['Side Chest Airbag-Driver', 'Side Chest Airbag-Passenger',\n","       'AEB Vulnerable Road Users', 'Side Head Airbag-Driver',\n","       'Side Head Airbag-Passenger', 'Seatbelt Reminder-Passenger',\n","       'AEB Car-to-Car', 'Belt Loadlimiter-Rear', 'Belt Pretensioner-Rear',\n","       'Side Head Airbag-Rear', 'Lane Assist System', 'Seatbelt Reminder-Rear',\n","       'Safety Assist', 'Speed Assistance', 'Adult Occupant',\n","       'Centre Airbag-Driver', 'Child Occupant', 'Tested Model',\n","       'Isofix/i-Size-Passenger'] '''\n","\n","dataFeatures= ['Adult Occupant', 'Belt Pretensioner-Rear', 'Safety Assist',\n","       'Child Occupant', 'Class', 'Side Pelvis Airbag-Rear',\n","       'AEB Vulnerable Road Users']\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['Adult Occupant', 'Belt Pretensioner-Rear', 'Safety Assist',\n","       'Child Occupant', 'Class', 'Side Pelvis Airbag-Rear',\n","       'AEB Vulnerable Road Users', 'Rate'],\n","      dtype='object')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# print the columns in the dataset\n","data.columns"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The range of feature inputs are within 0.0 to 1.0\n"]}],"source":["'''# Create a MinMaxScaler object for numrical data\n","scaler = MinMaxScaler()\n","\n","# Scaling the raw input features \n","feature_cols=data.columns[:-1]\n","X= scaler.fit_transform(data[feature_cols])\n","\n","print(f\"The range of feature inputs are within {X.min()} to {X.max()}\")'''"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2. Split the dataset "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training dataset shape, X_train: (217, 7), y_train: (217,)\n","Testing dataset shape, X_test: (94, 7), y_test: (94,)\n"]}],"source":["\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","feature_cols=data.columns[:-1]\n","# Get the split indexes\n","strat_shuf_split = StratifiedShuffleSplit(n_splits=1, \n","                                          test_size=0.3, random_state=0)\n","\n","train_idx, test_idx = next(strat_shuf_split.split(data[feature_cols], data['Rate']))\n","\n","# Create the dataframes\n","\n","\n","X_train = data.loc[train_idx, dataFeatures]\n","y_train = data.loc[train_idx, 'Rate']\n","\n","X_test  = data.loc[test_idx, dataFeatures]\n","y_test  = data.loc[test_idx, 'Rate']\n","\n","print(f\"Training dataset shape, X_train: {X_train.shape}, y_train: {y_train.shape}\")\n","print(f\"Testing dataset shape, X_test: {X_test.shape}, y_test: {y_test.shape}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3. Smoot "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["X= data.loc[:,dataFeatures]\n","y= data.loc[:,[\"Rate\"]]\n","\n","def splitSmote (model):\n","    # Initialize the Stratified K-fold Cross-validator with 5 splits\n","    sk=StratifiedKFold(n_splits=5)\n","\n","    # Initialize the array to store the accuracy scores\n","    accuracy_scores = []\n","\n","    # Perform cross-validation\n","    for train_index, test_index in sk.split(X, y):\n","        # Split the data into training and test sets\n","        x_train_fold, x_test_fold = X.loc[train_index,:], X.loc[test_index,:]\n","        y_train_fold, y_test_fold = y.loc[train_index,:], y.loc[test_index,:]\n","\n","        #smote = SMOTE(sampling_strategy='minority')\n","        smote = SMOTE(sampling_strategy=0.5)\n","        x_sm, y_sm = smote.fit_resample(x_train_fold, y_train_fold)\n","        #Fit the model to the training data\n","        model.fit(x_sm, y_sm)\n","        # Make predictions on the test data\n","        y_pred = model.predict(x_test_fold)\n","        # Calculate the accuracy score and append it to the list\n","        accuracy_scores.append(accuracy_score(y_test_fold, y_pred))\n","\n","\n","\n","    # Print the accuracy scores for each fold\n","    print(\"Accuracy scores for each fold: \", accuracy_scores)\n","\n","    # Calculate the mean accuracy scores\n","    print(\"Mean accuracy score: \", np.mean(accuracy_scores))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4. Data normalization "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["5    0.718894\n","4    0.161290\n","3    0.092166\n","1    0.009217\n","0    0.009217\n","2    0.009217\n","Name: Rate, dtype: float64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts(normalize=True)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["5    0.723404\n","4    0.159574\n","3    0.085106\n","2    0.010638\n","1    0.010638\n","0    0.010638\n","Name: Rate, dtype: float64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["y_test.value_counts(normalize=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4. Models "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4.1 Decision Tree "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["before optimization"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy scores for each fold:  [0.9523809523809523, 0.967741935483871, 0.7903225806451613, 0.9838709677419355, 0.7258064516129032]\n","Mean accuracy score:  0.8840245775729647\n"]}],"source":["# DecisionTreeClassifier\n","#importing the classfier\n","metrics=[]\n","\n","clf=DecisionTreeClassifier(random_state=0)\n","#clf2=clf.fit(X_train,y_train)\n","\n","\n","#y_pred.append(pd.Series(clf2.predict(X_test), name='DecisionTreeClassifier'))\n","# Preciision, recall, f-score from the multi-class support function\n","\n","# precision, recall, fscore, _ = score(y_test, clf2.predict(X_test), average='weighted')\n","# accuracy = accuracy_score(y_test, clf2.predict(X_test))\n","# metrics.append(pd.Series({'precision':precision, 'recall':recall,'fscore':fscore, 'accuracy':accuracy}))\n","\n","\n","splitSmote (clf)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["After optimization"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy scores for each fold:  [0.9365079365079365, 0.8870967741935484, 0.7903225806451613, 0.967741935483871, 0.7741935483870968]\n","Mean accuracy score:  0.8711725550435228\n"]}],"source":["# DecisionTree opt\n","\n","\n","#optimization\n","param_grid={\n","\"max_depth\":[2,4,6],\n","\"min_samples_split\":[2,5,10],\n","\"min_samples_leaf\":[1,2,4]}\n","grid_search= GridSearchCV(estimator=clf,param_grid=param_grid,cv=5)\n","\n","# grid_search.fit(X_train,y_train)\n","# print(\"Best hyper-param: \",grid_search.best_params_ )\n","# print(\"Best estimator: \",grid_search.best_estimator_ )\n","# print(\"Best score: \",grid_search.best_score_ )\n","\n","\n","# #precision, recall, fscore, _ = score(y_test, grid_search.predict(X_test), average='weighted')\n","# accuracy = accuracy_score(y_test, grid_search.predict(X_test))\n","# metrics.append(pd.Series({'precision':precision, 'recall':recall,'fscore':fscore, 'accuracy':accuracy}))\n","\n","\n","splitSmote (kCls)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["grid_search\n","Accuracy scores for each fold:  [0.9841269841269841, 0.9838709677419355, 0.7741935483870968, 0.9516129032258065, 0.6935483870967742]\n","Mean accuracy score:  0.8774705581157194\n"]}],"source":["#DT aftar opt\n","\n","print(\"grid_search\")\n","\n","splitSmote(grid_search)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4.2 KNN"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Before optimization"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy scores for each fold:  [0.9206349206349206, 0.9193548387096774, 0.7903225806451613, 0.9838709677419355, 0.7580645161290323]\n","Mean accuracy score:  0.8744495647721454\n"]}],"source":["# KNN\n","#importing the classfier\n","\n","kCls=KNeighborsClassifier()\n","splitSmote (kCls)\n","#kCls.fit(X_train,y_train)\n","\n","#y_pred.append(pd.Series(kCls.predict(X_test), name='KNeighborsClassifier'))\n","\n","#precision, recall, fscore, _ = score(y_test, kCls.predict(X_test), average='weighted')\n","#accuracy = accuracy_score(y_test, kCls.predict(X_test))\n","#metrics.append(pd.Series({'precision':precision, 'recall':recall,'fscore':fscore, 'accuracy':accuracy}))\n","\n","#kCls=KNeighborsClassifier(n_neighbors=9)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["After optimization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TODO: Write the code here"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4.3 GradientBoosting"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Before optimization"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy scores for each fold:  [0.9523809523809523, 0.967741935483871, 0.7903225806451613, 0.9516129032258065, 0.7419354838709677]\n","Mean accuracy score:  0.8807987711213517\n"]}],"source":["# GradientBoostingClassifier\n","#importing the classfier\n","\n","gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.1, max_features=4, max_depth=2, random_state=0)\n","#gb_clf2.fit(X_train, y_train)\n","\n","#y_pred.append(pd.Series(gb_clf2.predict(X_test), name='GradientBoostingClassifier'))\n","\n","#precision, recall, fscore, _ = score(y_test, gb_clf2.predict(X_test), average='weighted')\n","#accuracy = accuracy_score(y_test, gb_clf2.predict(X_test))\n","#metrics.append(pd.Series({'precision':precision, 'recall':recall,'fscore':fscore, 'accuracy':accuracy}))\n","\n","splitSmote (gb_clf2)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["After optimization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TODO: Write the code here"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4.4 LogisticRegression"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Before optimization"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy scores for each fold:  [0.9047619047619048, 0.9516129032258065, 0.7903225806451613, 0.9354838709677419, 0.6451612903225806]\n","Mean accuracy score:  0.8454685099846391\n"]}],"source":["#LogisticRegression\n","\n","#Grid search cross validation\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\",\"elasticnet\"], 'solver'  : ['newton-cg', 'lbfgs', 'liblinear']}\n","logreg=LogisticRegression()\n","lr=GridSearchCV(logreg,grid,cv=10)\n","# lr.fit(X_train,y_train)\n","\n","# a=lr.best_params_\n","# b=lr.best_score_\n","# print(\"tuned hpyerparameters :(best parameters) \",lr.best_params_)\n","# print(\"accuracy :\",lr.best_score_)\n","# print(\"Best estimator: \",lr.best_estimator_ )\n","\n","#y_pred.append(pd.Series(lr.predict(X_test), name='LogisticRegression'))\n","\n","# precision, recall, fscore, _ = score(y_test, lr.predict(X_test), average='weighted')\n","# accuracy = accuracy_score(y_test, lr.predict(X_test))\n","# metrics.append(pd.Series({'precision':precision, 'recall':recall,'fscore':fscore, 'accuracy':accuracy}))\n","\n","#LogisticRegression\n","#from sklearn.linear_model import LogisticRegressionCV\n","#lr= LogisticRegressionCV(Cs=a['C'], penalty=a['penalty'], solver=a['solver']).fit(X_train, y_train)\n","\n","splitSmote (lr)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["After optimization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TODO: write LogisticRegression optimization code here"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4.5 Random Forest"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Before optimization"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\rayoo\\AppData\\Local\\Temp\\ipykernel_45220\\3765096017.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(x_sm, y_sm)\n","C:\\Users\\rayoo\\AppData\\Local\\Temp\\ipykernel_45220\\3765096017.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(x_sm, y_sm)\n","C:\\Users\\rayoo\\AppData\\Local\\Temp\\ipykernel_45220\\3765096017.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(x_sm, y_sm)\n","C:\\Users\\rayoo\\AppData\\Local\\Temp\\ipykernel_45220\\3765096017.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(x_sm, y_sm)\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy scores for each fold:  [0.9365079365079365, 1.0, 0.7903225806451613, 0.9838709677419355, 0.7419354838709677]\n","Mean accuracy score:  0.8905273937532001\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\rayoo\\AppData\\Local\\Temp\\ipykernel_45220\\3765096017.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(x_sm, y_sm)\n"]}],"source":["#RandomForestClassifier\n","RF= RandomForestClassifier(criterion=\"gini\",\n","                           max_depth=8,\n","                           min_samples_split=10,\n","                           random_state= 0)\n","# RF.fit(X_train,y_train)\n","\n","# #y_pred.append(pd.Series(RF.predict(X_test), name='RandomForestClassifier'))\n","\n","# precision, recall, fscore, _ = score(y_test, RF.predict(X_test), average='weighted')\n","# accuracy = accuracy_score(y_test, RF.predict(X_test))\n","# metrics.append(pd.Series({'precision':precision, 'recall':recall,'fscore':fscore, 'accuracy':accuracy}))\n","\n","\n","splitSmote (RF)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["After optimization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TODO: Write RandomForest optimization code here"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 5. Training"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 5.1 Before Optimazation "]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["KNN\n","Accuracy scores for each fold:  [0.9365079365079365, 0.9193548387096774, 0.7903225806451613, 0.9516129032258065, 0.7741935483870968]\n","Mean accuracy score:  0.8743983614951356\n","GradientBoosting\n","Accuracy scores for each fold:  [0.9682539682539683, 1.0, 0.7903225806451613, 0.9838709677419355, 0.7419354838709677]\n","Mean accuracy score:  0.8968766001024064\n","LogisticRegression\n","Accuracy scores for each fold:  [0.9047619047619048, 1.0, 0.8225806451612904, 0.967741935483871, 0.6612903225806451]\n","Mean accuracy score:  0.8712749615975423\n","RandomForest\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\rayoo\\AppData\\Local\\Temp\\ipykernel_45220\\3765096017.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(x_sm, y_sm)\n","C:\\Users\\rayoo\\AppData\\Local\\Temp\\ipykernel_45220\\3765096017.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(x_sm, y_sm)\n","C:\\Users\\rayoo\\AppData\\Local\\Temp\\ipykernel_45220\\3765096017.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(x_sm, y_sm)\n","C:\\Users\\rayoo\\AppData\\Local\\Temp\\ipykernel_45220\\3765096017.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(x_sm, y_sm)\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy scores for each fold:  [0.9523809523809523, 1.0, 0.7903225806451613, 0.967741935483871, 0.7741935483870968]\n","Mean accuracy score:  0.8969278033794164\n","DecisionTree\n","Accuracy scores for each fold:  [0.9841269841269841, 0.967741935483871, 0.7903225806451613, 0.9516129032258065, 0.7096774193548387]\n","Mean accuracy score:  0.8806963645673322\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\rayoo\\AppData\\Local\\Temp\\ipykernel_45220\\3765096017.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(x_sm, y_sm)\n"]}],"source":["# Base models \n","kCls=KNeighborsClassifier()\n","print(\"KNN\")\n","splitSmote (kCls)\n","\n","gb_clf2 = GradientBoostingClassifier()\n","print(\"GradientBoosting\")\n","splitSmote (gb_clf2)\n","\n","logreg=LogisticRegression()\n","print(\"LogisticRegression\")\n","splitSmote (logreg)\n","\n","RF= RandomForestClassifier()\n","print(\"RandomForest\")\n","splitSmote (RF)\n","\n","clf=DecisionTreeClassifier()\n","print(\"DecisionTree\")\n","splitSmote (clf)\n","\n","\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### After Optimization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TODO: write the code here"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 5. Evaluation"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 5.1 Before Optimization"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["\n","def report( y_test, pred ):\n","    #report \n","    print(classification_report(y_test,pred,target_names=['0','1','2','3','4','5']))\n","\n","\n","def confusionMatrix():\n","    #confusion_matrix\n","    #the result will show how mwny sucessful predition and wrong from each class\n","\n","    cm = confusion_matrix(y_test, pred)\n","    plt.figure(figsize=(10,7))\n","\n","    sns.heatmap(cm, annot=True, fmt='.2g', cmap='Blues')\n","\n","    # TN   FP\n","    # FN   TP"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(metrics, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mDecisionTree\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mDecisionTreeOpt\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mKNN\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mGradientBoosting\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mLogisticRegression\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mRandomForest\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m metrics\u001b[39m.\u001b[39mcolumns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mDecisionTree\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mDecisionTreeOpt\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mKNN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mGradientBoosting\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mLogisticRegression\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m'\u001b[39m]\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/reshape/concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[1;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m    159\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m         objs,\n\u001b[1;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n","File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/reshape/concat.py:403\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    390\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    391\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     sort\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    401\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(objs, (ABCSeries, ABCDataFrame, \u001b[39mstr\u001b[39m)):\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    404\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfirst argument must be an iterable of pandas \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobjects, you passed an object of type \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(objs)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    406\u001b[0m         )\n\u001b[1;32m    408\u001b[0m     \u001b[39mif\u001b[39;00m join \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mouter\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    409\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintersect \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""]}],"source":["metrics = pd.concat(metrics, axis=1,names=['DecisionTree','DecisionTreeOpt','KNN','GradientBoosting','LogisticRegression','RandomForest'])\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DecisionTree</th>\n","      <th>DecisionTreeOpt</th>\n","      <th>KNN</th>\n","      <th>GradientBoosting</th>\n","      <th>LogisticRegression</th>\n","      <th>RandomForest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>precision</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.733490</td>\n","      <td>0.963374</td>\n","      <td>0.961147</td>\n","      <td>0.944874</td>\n","    </tr>\n","    <tr>\n","      <th>recall</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.776596</td>\n","      <td>0.968085</td>\n","      <td>0.968085</td>\n","      <td>0.968085</td>\n","    </tr>\n","    <tr>\n","      <th>fscore</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.749230</td>\n","      <td>0.963933</td>\n","      <td>0.962621</td>\n","      <td>0.954647</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.776596</td>\n","      <td>0.968085</td>\n","      <td>0.968085</td>\n","      <td>0.968085</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           DecisionTree  DecisionTreeOpt       KNN  GradientBoosting  \\\n","precision           1.0              1.0  0.733490          0.963374   \n","recall              1.0              1.0  0.776596          0.968085   \n","fscore              1.0              1.0  0.749230          0.963933   \n","accuracy            1.0              1.0  0.776596          0.968085   \n","\n","           LogisticRegression  RandomForest  \n","precision            0.961147      0.944874  \n","recall               0.968085      0.968085  \n","fscore               0.962621      0.954647  \n","accuracy             0.968085      0.968085  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["metrics.columns=['DecisionTree','DecisionTreeOpt','KNN','GradientBoosting','LogisticRegression','RandomForest']\n","metrics"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 5.2 After Optimization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#TODO: write the code here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
